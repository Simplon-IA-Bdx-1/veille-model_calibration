{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Calibration\n",
    "## ou l'amélioration de la distribution des erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Principe de la calibration de modèle en classification\n",
    "- Exemple\n",
    "- Pour aller plus loin...\n",
    "- Liens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La calibration de modèle est une opération de remise à l'échelle qui s'effectue **APRES** que les prédictions aient été faites par le modèle.\n",
    "\n",
    "Elle est utile en particulier pour les **SVM, les decision trees, random forests, et certains Neural Networks**.\n",
    "\n",
    "Elle consiste à **confronter la distribution des valeurs prédites par rapport à la probabilité de classe donnée à chaque prédiction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On n'y a jamais prêté attention auparavant dans nos travaux, mais a priori souvent les algorithmes de Machine Learning non-linéaires prédisent des probabilités de classe non-calibrées par défaut.\n",
    "\n",
    "Imaginons un modèle de classificateur binaire **bien calibré** qui prédirait un jeu de données.\n",
    "\n",
    "On analyse par exemple les prédictions Positives avec un **predict_proba de 0.8**\n",
    "\n",
    "-> on s'attendra donc à retrouver **80%** de ces prédictions dans les True Positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Note très importante: des probabilités mieux calibrées n'amènent pas forcément de meilleurs résultats de prédictions basées sur des probabilités de classes. Cela dépend vraiment de la métrique spécifique pour l'évaluation et du type de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Petit exemple sur un dataset fictif de 100k samples, avec 20 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pour aller plus loin\n",
    "- Que se passe-t-il lorsqu'on a un jeu de données d'entraînement avec des classes déséquilibrées ? \n",
    "- Quel est l'influence de l'utilisation du SMOTE (et autre data augmentation) sur la calibration ?\n",
    "- Peut-on calibrer des modèles de classification multi-classes ?\n",
    "- Que sont vraiment les fameux \"Gaussian naive Bayes \" qu'on commence à voir dans toutes les veilles ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Liens\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html\n",
    "\n",
    "https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf\n",
    "\n",
    "https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
